<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
    />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <header>
      <h1>Dzongkha Automatic Speech Recognition (ASR) System</h1>
    </header>

    <div class="main">
      <div class="aim-container">
        <div class="aim">
          <p>
            <spam class="title">Dzongkha Automatic Speech Recognition</spam
            ><br />
            The Dzongkha Speech Recognition System is an advanced technology
            that uses ML and AI algorithms to transcribe spoken Dzongkha
            language into text, making it easier for users to communicate and
            interact with technology in their native language.
          </p>
        </div>
      </div>
      <div class="obj-container">
        <div class="grid">
          <div class="grid-item">
            <img src="Data_coll.png" alt="Image" />
          </div>
          <div class="grid-item">
            <h2>Data collection and Preprocessing</h2>
            <p>
              We received around 16,236 datasets from the Dzongkha Development
              Commission in the form of an Excel file. Afterward, we
              preprocessed the dataset into the required format and stored the
              audio and transcription in different folders.
            </p>
          </div>
        </div>
        <div class="grid">
          <div class="grid-item">
            <h2>Implement different deep learning model</h2>
            <p>
              We have trained and tuned several models, including the
              Transformer model, XLS-R Wav2Vec2, and CNN-ResNet-BiLSTM. Among
              these models, we have selected XLS-R Wav2Vec2 as our base model
              due to its superior performance and efficiency.
            </p>
          </div>
          <div class="grid-item">
            <img src="train_tunin.png" alt="Image" />
          </div>
        </div>
        <div class="grid">
          <div class="grid-item">
            <img src="Dl.png" alt="Image" />
          </div>
          <div class="grid-item">
            <h2>Model tuning and training</h2>
            <p>
              Our base model is the XLS-R Wav2Vec2, which we trained and
              fine-tuned. In an effort to enhance its performance, we have
              implemented hyperparameter tuning.
            </p>
          </div>
        </div>
        <div class="grid">
          <div class="grid-item">
            <h2>Implement transfer learning techniques</h2>
            <p>
              XLS-R Wav2Vec2 is a state-of-the-art speech recognition model
              developed by Facebook AI Research. It is based on the Wave2Vec
              architecture and utilizes cross-lingual speech representations for
              improved performance on a wide range of languages.
            </p>
          </div>
          <div class="grid-item">
            <img src="T_learning.png" alt="Image" />
          </div>
        </div>
      </div>
    </div>

    <!-- About Project -->
    <div class="Abt_prj">
      <div class="prj-grid">
        <h2>
          About<br />
          <spam class="dzongkha">རྫོང་ཁ</spam><br />Automatic Speech Recognition
        </h2>
      </div>
      <div class="prj-grid">
        <p>
          The Dzongkha Automatic Speech Recognition (ASR) system is a project
          aimed at developing a technology that can accurately translate spoken
          Dzongkha into text. The project involves using advanced machine
          learning algorithms and deep neural networks to train the system to
          recognize and transcribe Dzongkha speech. The system will be able to
          recognize various accents and dialects of the language and convert the
          spoken words into written text in real-time.
        </p>
        <p>
          It will help to promote the use of Dzongkha in modern communication
          technology and make it easier for Bhutanese people to communicate in
          their native language. It will also help to preserve the language and
          culture of Bhutan by making it easier to document and store Dzongkha
          content.
        </p>
        <p>
          Dzongkha is a tonal language with complex pronunciation rules, which
          makes it difficult to train a speech recognition system. Additionally,
          there is a lack of high-quality training data, which is essential for
          the development of accurate speech recognition models. Despite these
          challenges, the Dzongkha ASR system has the potential to revolutionize
          communication technology in Bhutan and make the language more
          accessible to its speakers.
        </p>
      </div>
    </div>

    <div class="card-container">
      <h1>Team</h1>
      <div class="cards">
        <div class="card">
          <div class="img-container">
            <img src="sir.jpg" alt="" style="height: 235px" />
          </div>
          <h3>Pema Galey</h3>
          <p>Guide</p>
          <div class="icons">
            <a href="#">
              <i class="fa-brands fa-linkedin"></i>
            </a>
            <a href="#">
              <i class="fa-brands fa-github"></i>
            </a>
            <a href="#">
              <i class="fa-solid fa-envelope"></i>
            </a>
          </div>
        </div>
        <!-- member1 -->
        <div class="card">
          <div class="img-container">
            <img src="NSP.jpg" alt="" />
          </div>
          <h3>Ngawang Samten Pelzang</h3>
          <p>Developer</p>
          <div class="icons">
            <a href="#">
              <i class="fa-brands fa-linkedin"></i>
            </a>
            <a href="#">
              <i class="fa-brands fa-github"></i>
            </a>
            <a href="#">
              <i class="fa-solid fa-envelope"></i>
            </a>
          </div>
        </div>

        <!-- Member2 -->
        <div class="card">
          <div class="img-container">
            <img src="KR.jpg" alt="" />
          </div>
          <h3>Kinley Rabgay</h3>
          <p>Developer</p>
          <div class="icons">
            <a href="#">
              <i class="fa-brands fa-linkedin"></i>
            </a>
            <a href="#">
              <i class="fa-brands fa-github"></i>
            </a>
            <a href="#">
              <i class="fa-solid fa-envelope"></i>
            </a>
          </div>
        </div>

        <!-- Member3 -->
        <div class="card">
          <div class="img-container">
            <img src="Kenji.jpg" alt="" />
          </div>
          <h3>Khentse Dorji</h3>
          <p>Developer</p>
          <div class="icons">
            <a href="#">
              <i class="fa-brands fa-linkedin"></i>
            </a>
            <a href="#">
              <i class="fa-brands fa-github"></i>
            </a>
            <a href="#">
              <i class="fa-solid fa-envelope"></i>
            </a>
          </div>
        </div>
      </div>
    </div>
    <footer>
      <p>&copy; 2023 - About Us</p>
    </footer>
  </body>
</html>
